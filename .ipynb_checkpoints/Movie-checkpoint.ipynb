{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e6b858-cec8-476c-ae6c-f9b6743d2b39",
   "metadata": {},
   "source": [
    "# ğŸ¬ Movie Assignment\n",
    "\n",
    "### ğŸ‘¥ Group 3  \n",
    "**Members:**  \n",
    "- Kanika Rawat  \n",
    "- Kavya Mehta  \n",
    "- Nisarg Sheth  \n",
    "- Prathamesh Shukla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e94a3a7-1b1b-4171-84d7-eb3609193dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install prereq libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b239402-914a-4f5d-bc0a-ed3850850c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.13/site-packages (11.1.0)\n",
      "Requirement already satisfied: pillow-heif in /opt/anaconda3/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: reportlab in /opt/anaconda3/lib/python3.13/site-packages (4.4.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/lib/python3.13/site-packages (from reportlab) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy pillow pillow-heif reportlab pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3857b00-7260-46e0-a3b2-74bbcc1b9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from reportlab.platypus import BaseDocTemplate, PageTemplate, Frame, PageBreak\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "import pillow_heif\n",
    "import cv2\n",
    "import numpy as np\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6f5e6b-1fde-46d8-9d92-18dae9b93e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fonts loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "csv_file = \"https://docs.google.com/spreadsheets/d/142o7HYj94O2AMogtvE9XWYQxYxGrnJWwnHJ3CT6j-u0/export?format=csv&gid=1659935786\"\n",
    "image_folder = \"images\"\n",
    "output_folder = \"output_pdfs\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Register HEIF opener\n",
    "pillow_heif.register_heif_opener()\n",
    "\n",
    "# --- Font Registration ---\n",
    "# Define font paths for each language\n",
    "FONT_MAP = {\n",
    "    'English': 'NotoSans-Regular.ttf',\n",
    "    'Hindi': 'NotoSansDevanagari-Regular.ttf',\n",
    "    'Chinese': 'NotoSansSC-Regular.ttf',\n",
    "    'Greek': 'NotoSans-Regular.ttf'  # NotoSans supports Greek characters\n",
    "}\n",
    "\n",
    "try:\n",
    "    pdfmetrics.registerFont(TTFont('NotoSans', 'NotoSans-Regular.ttf'))\n",
    "    pdfmetrics.registerFont(TTFont('NotoSansDevanagari', 'NotoSansDevanagari-Regular.ttf'))\n",
    "    pdfmetrics.registerFont(TTFont('NotoSansSC', 'NotoSansSC-Regular.ttf'))\n",
    "    print(\"All fonts loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Font loading error: {e}\")\n",
    "    print(\"Please ensure NotoSans-Regular.ttf, NotoSansDevanagari-Regular.ttf, and NotoSansSC-Regular.ttf are in the script's directory.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f54fba9-aa8e-4c77-83df-88c951e2a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data imported successfully!\n",
      "                                           English  \\\n",
      "0               Every dream job hides a nightmare.   \n",
      "1  Miranda:You are late. Fashion waits for no one.   \n",
      "2                      Emily:He won't last a week.   \n",
      "3                               Nigel:No one does.   \n",
      "4             Andy:I can handle pressure can't  I?   \n",
      "\n",
      "                                               Hindi                  Chinese  \\\n",
      "0  à¤¹à¤° à¤¸à¤ªà¤¨à¥‹à¤‚ à¤µà¤¾à¤²à¥€ à¤¨à¥Œà¤•à¤°à¥€ à¤•à¥‡ à¤ªà¥€à¤›à¥‡ à¤à¤• à¤¦à¥à¤ƒà¤¸à¥à¤µà¤ªà¥à¤¨ à¤›à¤¿à¤ªà¤¾ ...         æ¯ä¸ªæ¢¦æƒ³çš„å·¥ä½œèƒŒåéƒ½éšè—ç€å™©æ¢¦ã€‚   \n",
      "1  Miranda: à¤¤à¥à¤® à¤¦à¥‡à¤° à¤¸à¥‡ à¤†à¤ˆ à¤¹à¥‹à¥¤ à¤«à¤¼à¥ˆà¤¶à¤¨ à¤•à¤¿à¤¸à¥€ à¤•à¤¾ à¤‡à¤‚à¤¤à¤œà¤¼...  Miranda: ä½ è¿Ÿåˆ°äº†ã€‚æ—¶å°šä¸ä¼šç­‰ä»»ä½•äººã€‚   \n",
      "2                 Emily: à¤µà¤¹ à¤à¤• à¤¹à¤«à¥à¤¤à¥‡ à¤­à¥€ à¤¨à¤¹à¥€à¤‚ à¤Ÿà¤¿à¤•à¥‡à¤—à¥€à¥¤         Emily: å¥¹æ’‘ä¸è¿‡ä¸€ä¸ªæ˜ŸæœŸã€‚   \n",
      "3                          Nigel: à¤•à¥‹à¤ˆ à¤­à¥€ à¤¨à¤¹à¥€à¤‚ à¤Ÿà¤¿à¤•à¤¤à¤¾à¥¤           Nigel: æ²¡æœ‰äººèƒ½æ’‘ä½ã€‚   \n",
      "4                Andy: à¤®à¥ˆà¤‚ à¤¦à¤¬à¤¾à¤µ à¤à¥‡à¤² à¤¸à¤•à¤¤à¥€ à¤¹à¥‚à¤, à¤¹à¥ˆ à¤¨à¤¾?         Andy: æˆ‘èƒ½æ‰¿å—å‹åŠ›ï¼Œå¯¹å§ï¼Ÿ   \n",
      "\n",
      "                                              Greek    Images  \n",
      "0     ÎšÎ¬Î¸Îµ Î´Î¿Ï…Î»ÎµÎ¹Î¬ Ï„Ï‰Î½ Î¿Î½ÎµÎ¯ÏÏ‰Î½ ÎºÏÏÎ²ÎµÎ¹ Î­Î½Î±Î½ ÎµÏ†Î¹Î¬Î»Ï„Î·.    1.HEIC  \n",
      "1   ÎœÎ¹ÏÎ¬Î½Ï„Î±: Î†ÏÎ³Î·ÏƒÎµÏ‚. Î— Î¼ÏŒÎ´Î± Î´ÎµÎ½ Ï€ÎµÏÎ¹Î¼Î­Î½ÎµÎ¹ ÎºÎ±Î½Î­Î½Î±Î½.    2.HEIC  \n",
      "2          ÎˆÎ¼Î¹Î»Î¹: Î”ÎµÎ½ Î¸Î± Î±Î½Ï„Î­Î¾ÎµÎ¹ Î¿ÏÏ„Îµ Î¼Î¹Î± ÎµÎ²Î´Î¿Î¼Î¬Î´Î±.    3.HEIC  \n",
      "3                      ÎÎ¬Î¹Ï„Î¶ÎµÎ»: ÎšÎ±Î½ÎµÎ¯Ï‚ Î´ÎµÎ½ Î±Î½Ï„Î­Ï‡ÎµÎ¹.  3-1.HEIC  \n",
      "4  Î†Î½Ï„Î¹: ÎœÏ€Î¿ÏÏ Î½Î± Î±Î½Ï„Î­Î¾Ï‰ Ï„Î·Î½ Ï€Î¯ÎµÏƒÎ·, Î­Ï„ÏƒÎ¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹;    4.HEIC  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading ---\n",
    "df = pd.read_csv(csv_file, header=0)\n",
    "dialogs_data = {\n",
    "    'English': df.iloc[:, 0].tolist(),\n",
    "    'Hindi': df.iloc[:, 1].tolist(),\n",
    "    'Chinese': df.iloc[:, 2].tolist(),\n",
    "    'Greek': df.iloc[:, 3].tolist()  # FIXED: Changed from column 2 to column 3\n",
    "}\n",
    "image_files = df.iloc[:, 4].tolist()\n",
    "\n",
    "print(\"CSV data imported successfully!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3397c67f-fa9b-41b0-9c5c-d32f6d005805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scary_filter(pil_image):\n",
    "    \"\"\"\n",
    "    Make an image look scarier: deep contrast, cold shadows, boosted reds,\n",
    "    inked edges, heavy vignette, subtle motion smear, film grain, and\n",
    "    slight chromatic aberration.\n",
    "    \"\"\"\n",
    "    has_alpha = pil_image.mode == \"RGBA\"\n",
    "    if has_alpha:\n",
    "        base_rgb = pil_image.convert(\"RGB\")\n",
    "        alpha = np.array(pil_image.split()[-1])\n",
    "    else:\n",
    "        base_rgb = pil_image\n",
    "\n",
    "    bgr = cv2.cvtColor(np.array(base_rgb), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 1) Local contrast boost (CLAHE in LAB)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    L = clahe.apply(L)\n",
    "    lab = cv2.merge([L, A, B])\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # 2) Desaturate overall slightly (bleak base)\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    s = cv2.convertScaleAbs(s, alpha=0.8, beta=0)\n",
    "    hsv = cv2.merge([h, s, v])\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # 3) Boost reds selectively (make bloody tones pop)\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    lower_red1 = np.array([0, 120, 60], dtype=np.uint8)\n",
    "    upper_red1 = np.array([10, 255, 255], dtype=np.uint8)\n",
    "    lower_red2 = np.array([170, 120, 60], dtype=np.uint8)\n",
    "    upper_red2 = np.array([180, 255, 255], dtype=np.uint8)\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "    h_, s_, v_ = cv2.split(hsv)\n",
    "    s_ = cv2.add(s_, 70, dst=s_, mask=red_mask)\n",
    "    v_ = cv2.add(v_, 25, dst=v_, mask=red_mask)\n",
    "    hsv = cv2.merge([h_, s_, v_])\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # 4) Split toning (cold shadows, neutral highlights)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_f = gray.astype(np.float32) / 255.0\n",
    "    shadows = 1.0 - gray_f\n",
    "    shadows = cv2.GaussianBlur(shadows, (0, 0), 3)\n",
    "\n",
    "    bgr_f = bgr.astype(np.float32) / 255.0\n",
    "    cool = bgr_f.copy()\n",
    "    cool[:, :, 0] = np.clip(cool[:, :, 0] + 0.10 * shadows, 0, 1)\n",
    "    cool[:, :, 1] = np.clip(cool[:, :, 1] + 0.05 * shadows, 0, 1)\n",
    "    cool[:, :, 2] = np.clip(cool[:, :, 2] - 0.05 * shadows, 0, 1)\n",
    "\n",
    "    bgr = (np.clip(cool, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    # 5) \"Inked\" edges overlay\n",
    "    edges = cv2.Canny(gray, 80, 160)\n",
    "    edges = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    edges_inv = cv2.bitwise_not(edges)\n",
    "    edges_mask = (edges_inv.astype(np.float32) / 255.0)[..., None]\n",
    "    bgr_f = bgr.astype(np.float32) / 255.0\n",
    "    inked = np.clip(bgr_f * (0.85 + 0.15 * edges_mask), 0, 1)\n",
    "    bgr = (inked * 255).astype(np.uint8)\n",
    "\n",
    "    # 6) Heavy vignette (focus to center, dark edges)\n",
    "    rows, cols = bgr.shape[:2]\n",
    "    kernel_x = cv2.getGaussianKernel(cols, cols / 3.0)\n",
    "    kernel_y = cv2.getGaussianKernel(rows, rows / 3.0)\n",
    "    kernel = kernel_y @ kernel_x.T\n",
    "    mask = kernel / kernel.max()\n",
    "    vignette_strength = 0.45\n",
    "    vignette = (1.0 - vignette_strength) + vignette_strength * mask\n",
    "    bgr_v = (bgr.astype(np.float32) * vignette[..., None]).clip(0, 255).astype(np.uint8)\n",
    "    bgr = bgr_v\n",
    "\n",
    "    # 7) Subtle motion smear (adds unease)\n",
    "    k = 7\n",
    "    motion = np.zeros((k, k), dtype=np.float32)\n",
    "    np.fill_diagonal(motion, 1.0)\n",
    "    motion /= motion.sum()\n",
    "    smeared = cv2.filter2D(bgr, -1, motion)\n",
    "    bgr = cv2.addWeighted(bgr, 0.8, smeared, 0.2, 0)\n",
    "\n",
    "    # 8) Film grain (monochrome noise)\n",
    "    noise = np.random.normal(0, 10, (rows, cols)).astype(np.float32)\n",
    "    for c in range(3):\n",
    "        chan = bgr[:, :, c].astype(np.float32)\n",
    "        chan = np.clip(chan + noise, 0, 255)\n",
    "        bgr[:, :, c] = chan.astype(np.uint8)\n",
    "\n",
    "    # 9) Chromatic aberration (subtle channel shift)\n",
    "    def shift_channel(channel, dx, dy):\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        return cv2.warpAffine(channel, M, (cols, rows), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    B, G, R = cv2.split(bgr)\n",
    "    R_shift = shift_channel(R, 1, 1)\n",
    "    B_shift = shift_channel(B, -1, -1)\n",
    "    bgr = cv2.merge([B_shift, G, R_shift])\n",
    "\n",
    "    # 10) Final global contrast/black lift\n",
    "    bgr = cv2.convertScaleAbs(bgr, alpha=1.25, beta=-15)\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    out = PILImage.fromarray(rgb)\n",
    "    if has_alpha:\n",
    "        out = out.convert(\"RGBA\")\n",
    "        out.putalpha(PILImage.fromarray(alpha))\n",
    "    else:\n",
    "        out = out.convert(\"RGBA\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbf7af9-4f98-4319-9fb8-32a3f8f1a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, font, max_width, draw):\n",
    "    \"\"\"Wraps text to fit within max_width, returning a list of lines.\"\"\"\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "    \n",
    "    for word in words:\n",
    "        test_line = ' '.join(current_line + [word])\n",
    "        bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "        test_width = bbox[2] - bbox[0]\n",
    "        \n",
    "        if test_width <= max_width:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "                current_line = [word]\n",
    "            else:\n",
    "                lines.append(word)\n",
    "                current_line = []\n",
    "    \n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4814607a-3edd-4d53-8ca8-957a52296120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, text, font_path, output_size, output_path):\n",
    "    \"\"\"Applies a filter, resizes with padding, and adds a caption with text wrapping.\"\"\"\n",
    "    try:\n",
    "        img = PILImage.open(image_path).convert(\"RGBA\")\n",
    "\n",
    "        quality_multiplier = 2.0\n",
    "        target_size = (int(output_size[0] * quality_multiplier), \n",
    "                       int(output_size[1] * quality_multiplier))\n",
    "\n",
    "        img.thumbnail(target_size, PILImage.Resampling.LANCZOS)\n",
    "\n",
    "        filtered_img_content = apply_scary_filter(img)\n",
    "        \n",
    "        background = PILImage.new('RGBA', target_size, (0, 0, 0, 255))\n",
    "        filtered_img_content.thumbnail(target_size, PILImage.Resampling.LANCZOS)\n",
    "\n",
    "        paste_x = (target_size[0] - filtered_img_content.width) // 2\n",
    "        paste_y = (target_size[1] - filtered_img_content.height) // 2\n",
    "        background.paste(filtered_img_content, (paste_x, paste_y))\n",
    "        \n",
    "        if text and str(text).strip().lower() not in ['nan', 'none', '']:\n",
    "            draw = ImageDraw.Draw(background)\n",
    "            font_size = int(target_size[0] / 25)\n",
    "            \n",
    "            # Use the correct font file for this language\n",
    "            font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "            max_text_width = int(background.width * 0.90)\n",
    "            text_lines = wrap_text(text, font, max_text_width, draw)\n",
    "            \n",
    "            line_height = font_size * 1.2\n",
    "            total_text_height = len(text_lines) * line_height\n",
    "            start_y = background.height - total_text_height - (background.height * 0.05)\n",
    "            \n",
    "            max_line_width = 0\n",
    "            for line in text_lines:\n",
    "                bbox = draw.textbbox((0, 0), line, font=font)\n",
    "                line_width = bbox[2] - bbox[0]\n",
    "                max_line_width = max(max_line_width, line_width)\n",
    "            \n",
    "            box_padding = int(font_size * 0.2)\n",
    "            box_x = (background.width - max_line_width) / 2\n",
    "            box_coords = [\n",
    "                box_x - box_padding,\n",
    "                start_y - box_padding,\n",
    "                box_x + max_line_width + box_padding,\n",
    "                start_y + total_text_height + box_padding\n",
    "            ]\n",
    "            draw.rectangle(box_coords, fill=(40, 40, 40, 180))\n",
    "            \n",
    "            stroke_width = 2\n",
    "            current_y = start_y\n",
    "            \n",
    "            for line in text_lines:\n",
    "                bbox = draw.textbbox((0, 0), line, font=font)\n",
    "                line_width = bbox[2] - bbox[0]\n",
    "                x = (background.width - line_width) / 2\n",
    "                \n",
    "                for offset in [(dx, dy) for dx in range(-stroke_width, stroke_width + 1) \n",
    "                              for dy in range(-stroke_width, stroke_width + 1)]:\n",
    "                    draw.text((x + offset[0], current_y + offset[1]), line, font=font, fill=\"black\")\n",
    "                \n",
    "                draw.text((x, current_y), line, font=font, fill=\"white\")\n",
    "                current_y += line_height\n",
    "        \n",
    "        background.convert(\"RGB\").save(output_path, \"JPEG\", quality=92, optimize=True, subsampling=0)\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c27f97d-c385-42cd-9d97-c83d0052cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf(dialogs, lang_name, output_file):\n",
    "    \"\"\"Creates the PDF using manual, precise image placement.\"\"\"\n",
    "    doc = BaseDocTemplate(output_file, pagesize=A4)\n",
    "    \n",
    "    page_width, page_height = A4\n",
    "    images_per_page = 12\n",
    "    cols, rows = 3, 4\n",
    "    cell_width = page_width / cols\n",
    "    cell_height = page_height / rows\n",
    "    \n",
    "    quality_multiplier = 2.0\n",
    "    output_size = (int(cell_width * quality_multiplier), int(cell_height * quality_multiplier))\n",
    "    \n",
    "    # Get the correct font for this language\n",
    "    font_path = FONT_MAP.get(lang_name, 'NotoSans-Regular.ttf')\n",
    "    \n",
    "    temp_files = []\n",
    "    \n",
    "    def on_page(canvas, doc):\n",
    "        \"\"\"This function is called for each new page and draws the content.\"\"\"\n",
    "        canvas.saveState()\n",
    "        canvas.setFillColor(colors.black)\n",
    "        canvas.rect(0, 0, page_width, page_height, fill=1, stroke=0)\n",
    "        \n",
    "        page_num = canvas.getPageNumber()\n",
    "        start_index = (page_num - 1) * images_per_page\n",
    "        \n",
    "        for i in range(images_per_page):\n",
    "            image_index = start_index + i\n",
    "            if image_index < len(image_files):\n",
    "                row, col = i // cols, i % cols\n",
    "                x = col * cell_width\n",
    "                y = page_height - (row + 1) * cell_height\n",
    "                \n",
    "                img_path = os.path.join(image_folder, image_files[image_index])\n",
    "                dialog_text = str(dialogs[image_index])\n",
    "                temp_img_path = f\"temp_{lang_name}_{image_index}.jpg\"\n",
    "                \n",
    "                # Pass the correct font path for this language\n",
    "                processed_path = process_image(img_path, dialog_text, font_path, output_size, temp_img_path)\n",
    "                \n",
    "                if processed_path:\n",
    "                    canvas.drawImage(processed_path, x, y, width=cell_width, height=cell_height)\n",
    "                    temp_files.append(processed_path)\n",
    "        canvas.restoreState()\n",
    "\n",
    "    full_page_frame = Frame(0, 0, page_width, page_height, id='full_page_frame')\n",
    "    main_template = PageTemplate(id='main', frames=[full_page_frame], onPage=on_page)\n",
    "    doc.addPageTemplates([main_template])\n",
    "    \n",
    "    num_pages = (len(image_files) + images_per_page - 1) // images_per_page\n",
    "    story = [PageBreak()] * num_pages\n",
    "    \n",
    "    doc.build(story)\n",
    "    \n",
    "    for path in set(temp_files):\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "            \n",
    "    print(f\"{lang_name} PDF saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268ec5bb-b204-48c9-b7b1-04aa6555a56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English PDF saved as output_pdfs/dialogs_english.pdf\n",
      "Hindi PDF saved as output_pdfs/dialogs_hindi.pdf\n",
      "Chinese PDF saved as output_pdfs/dialogs_chinese.pdf\n",
      "Greek PDF saved as output_pdfs/dialogs_greek.pdf\n",
      "All PDFs created successfully!\n"
     ]
    }
   ],
   "source": [
    "for lang, dialogs in dialogs_data.items():\n",
    "    output_filename = os.path.join(output_folder, f\"dialogs_{lang.lower()}.pdf\")\n",
    "    create_pdf(dialogs, lang, output_filename)\n",
    "\n",
    "print(\"All PDFs created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd803a-dc1d-4436-922d-8ba95422093c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
